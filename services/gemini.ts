
import { GoogleGenAI } from "@google/genai";
import { PeriodLog, CyclePhase } from '../types';
import { getValidAdviceFromCache, saveAdviceToCache } from './storage';

// æš–å¿ƒæœ¬åœ°æ–‡æ¡ˆåº“
const FALLBACK_ADVICE: Record<string, string> = {
  'æœˆç»æœŸ': "å®è´ï¼Œç°åœ¨æ˜¯ç‰¹æ®Šæ—¶æœŸï¼Œè‚šå­å¯èƒ½ä¸èˆ’æœã€‚è®°å¾—å¤šå–æš–æš–çš„çº¢ç³–å§œèŒ¶ï¼Œæ—©ç‚¹ä¼‘æ¯ï¼Œæˆ‘ä¼šä¸€ç›´é™ªç€ä½ çš„ã€‚â¤ï¸",
  'åµæ³¡æœŸ': "ç”Ÿç†æœŸç»ˆäºç»“æŸå•¦ï¼ç°åœ¨æ˜¯ä½ çš„é»„é‡‘å˜ç¾æœŸï¼Œèº«ä½“ä»£è°¢åŠ å¿«ï¼Œå¿ƒæƒ…ä¹Ÿä¼šè¶Šæ¥è¶Šå¥½ï¼Œè¦ä¸è¦ä¸€èµ·å‡ºå»æ•£æ•£æ­¥ï¼Ÿâœ¨",
  'æ’åµæœŸ': "ç°åœ¨èº«ä½“çŠ¶æ€æœ€æ£’å•¦ï¼çš®è‚¤ä¹Ÿä¼šå¾ˆæœ‰å…‰æ³½ã€‚è®°å¾—å¤šè¡¥å……æ°´åˆ†ï¼Œä¿æŒæ´»åŠ›æ»¡æ»¡å“¦ã€‚ğŸ¥°",
  'é»„ä½“æœŸ': "æœ€è¿‘å¯èƒ½ä¼šè§‰å¾—æœ‰ç‚¹ç´¯æˆ–è€…æƒ…ç»ªæ³¢åŠ¨ï¼Œè¿™æ˜¯æ­£å¸¸çš„ç”Ÿç†ç°è±¡ã€‚æˆ‘ä¼šæ›´åŠ æ¸©æŸ”åœ°ç…§é¡¾ä½ ï¼Œç´¯äº†å°±é åœ¨æˆ‘è‚©è†€ä¸Šã€‚ğŸ«‚",
  'æœªçŸ¥': "æ¬¢è¿å¼€å¯ç‡•å­ç»æœŸï¼è®°å½•ç¬¬ä¸€æ¡æ•°æ®ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆä¸“å±çš„å® çˆ±ç­–ç•¥ã€‚ğŸŒ¸"
};

// å›ºå®šè¯é¢˜å…³é”®å­—ï¼Œç”¨äºè§¦å‘æµå¼ç¼“å­˜
const FIXED_TOPICS = ["ç¦å¿Œ", "ä¸èƒ½åƒ", "æ€ä¹ˆåŠ", "çº¢ç³–æ°´", "æ´—å¤´", "è¿åŠ¨", "é£Ÿè°±", "ç§‘æ™®"];

const fetchWithRetry = async (fn: () => Promise<any>, retries = 2, delay = 1500): Promise<any> => {
  try {
    return await fn();
  } catch (error: any) {
    const errorMsg = error?.message || "";
    if (errorMsg.includes("429") || errorMsg.includes("RESOURCE_EXHAUSTED")) {
      console.warn("Gemini API Quota exceeded (429). Switching to fallback mode.");
      throw error;
    }
    if (retries === 0) throw error;
    await new Promise(resolve => setTimeout(resolve, delay));
    return fetchWithRetry(fn, retries - 1, delay * 2);
  }
};

/**
 * æµå¼å¥åº·å»ºè®®è·å–ï¼Œå¸¦ç¼“å­˜æ£€æŸ¥
 */
export const getHealthAdviceStream = async (
  currentPhase: CyclePhase,
  recentLogs: PeriodLog[],
  userQuery: string,
  onChunk: (text: string) => void
): Promise<void> => {
  // 1. ä¼˜å…ˆæ£€æŸ¥ç¼“å­˜
  const cachedContent = getValidAdviceFromCache(currentPhase, userQuery);
  if (cachedContent) {
    console.debug("Streaming from cache:", userQuery);
    onChunk(cachedContent);
    return;
  }

  try {
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const latestLog = recentLogs.length > 0 ? recentLogs[0] : null;
    
    let cycleContext = latestLog 
      ? `- å‘¨æœŸç¬¬ ${Math.ceil(Math.abs(Date.now() - new Date(latestLog.startDate).getTime()) / 86400000)} å¤©ï¼Œé˜¶æ®µ: ${currentPhase}ã€‚`
      : `- é˜¶æ®µ: ${currentPhase}ã€‚`;

    const prompt = `
      ä½ æ˜¯ä¸€ä½æå…¶æ¸©æŸ”çš„ç”·æœ‹å‹ä¸“å®¶ã€‚
      èƒŒæ™¯ï¼š${cycleContext}
      ç”¨æˆ·æé—®ï¼š"${userQuery}"
      è¦æ±‚ï¼š
      1. å¼€å¤´ç”¨å® æººè¯­æ°”ã€‚
      2. ç»™å‡º 3 æ¡å®ç”¨å»ºè®®ï¼Œå¤šç”¨ emojiã€‚
      3. ä¸¥ç¦ä½¿ç”¨åŠ ç²—ç¬¦å·ï¼ˆ**ï¼‰ã€‚
      4. 200å­—ä»¥å†…ã€‚
    `;

    const result = await ai.models.generateContentStream({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: { temperature: 0.8 }
    });

    let fullText = '';
    for await (const chunk of result) {
      const chunkText = chunk.text;
      if (chunkText) {
        fullText += chunkText;
        onChunk(fullText);
      }
    }

    // 2. è‡ªåŠ¨ä¿å­˜ç»“æœåˆ°ç¼“å­˜
    if (fullText.length > 30) {
      saveAdviceToCache(fullText, currentPhase, userQuery);
    }

  } catch (error: any) {
    console.error("Stream Error:", error);
    const errorMsg = error?.message || "";
    if (errorMsg.includes("429")) {
      onChunk("å®è´ï¼Œæˆ‘åˆšæ‰è¢«å¤ªå¤šäººå’¨è¯¢å•¦ï¼ˆé…é¢è¶…é™ï¼‰ï¼Œä¸è¿‡æˆ‘å¯¹ä½ çš„å…³å¿ƒä¸æ‰“æŠ˜ï¼šæœ€è¿‘è¦è®°å¾—å¤šå–æš–æ°´ï¼Œæˆ‘ä¼šä¸€ç›´å®ˆæŠ¤ä½ çš„ã€‚â¤ï¸");
    } else {
      onChunk("âš ï¸ ç½‘ç»œè¿æ¥æœ‰äº›è°ƒçš®ï¼Œè¯·å°è¯•ç¨åå†è¯•ã€‚");
    }
  }
};

/**
 * è·å–å¥åº·å»ºè®®ï¼ˆéæµå¼ï¼‰
 */
export const getHealthAdvice = async (
  currentPhase: CyclePhase,
  recentLogs: PeriodLog[],
  userQuery?: string
): Promise<string> => {
  // 1. ä¼˜å…ˆä»ç¼“å­˜è·å–
  const cachedAdvice = getValidAdviceFromCache(currentPhase, userQuery);
  if (cachedAdvice) {
    return cachedAdvice;
  }

  // 2. ç¼“å­˜æœªå‘½ä¸­ï¼Œè°ƒç”¨ API
  try {
    const advice = await fetchWithRetry(async () => {
      const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
      const prompt = userQuery 
        ? `ä½ æ˜¯æ¸©æŸ”ç”·å‹ï¼Œé’ˆå¯¹æé—® "${userQuery}" ç»™å‡ºå»ºè®®ã€‚å½“å‰é˜¶æ®µ ${currentPhase}ã€‚ä¸ç”¨åŠ ç²—ç¬¦å·ã€‚`
        : `ä½ æ˜¯ä½“è´´ç”·å‹åŠ©æ‰‹ã€‚åŸºäºå¥³å‹å¤„äº ${currentPhase} é˜¶æ®µï¼Œç”Ÿæˆä¸€æ®µ100å­—å†…çš„ä»Šæ—¥ç…§é¡¾å»ºè®®ã€‚åŒ…å«èº«ä½“è§£ç ã€è¡ŒåŠ¨æ¸…å•ã€‚å¤šç”¨ emojiï¼Œä¸ç”¨åŠ ç²—ç¬¦å·ã€‚`;

      const response = await ai.models.generateContent({
        model: 'gemini-3-flash-preview',
        contents: prompt,
      });

      return response.text || FALLBACK_ADVICE[currentPhase] || FALLBACK_ADVICE['æœªçŸ¥'];
    });

    // 3. ç»“æœå­˜å…¥ç¼“å­˜
    saveAdviceToCache(advice, currentPhase, userQuery);

    return advice;
  } catch (error: any) {
    console.warn("Returning fallback advice due to API error/quota");
    return FALLBACK_ADVICE[currentPhase] || FALLBACK_ADVICE['æœªçŸ¥'];
  }
};
